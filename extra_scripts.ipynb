{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average-mean-tabpfn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder with CSV files\n",
    "folder = \"\"\n",
    "files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "# List to store all DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read and accumulate data\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all files into a single DataFrame\n",
    "df_total = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Check if 'threshold' column is present\n",
    "if 'threshold' not in df_total.columns:\n",
    "    raise ValueError(\"The column 'threshold' was not found in the CSV files.\")\n",
    "\n",
    "# Remove non-numeric columns except 'threshold'\n",
    "numeric_columns = df_total.select_dtypes(include='number').columns.tolist()\n",
    "if 'threshold' not in numeric_columns:\n",
    "    numeric_columns.insert(0, 'threshold')\n",
    "\n",
    "df_total = df_total[numeric_columns]\n",
    "\n",
    "# Group by 'threshold' and calculate mean and standard deviation\n",
    "mean_df = df_total.groupby('threshold').mean()\n",
    "std_df = df_total.groupby('threshold').std()\n",
    "\n",
    "# Add column indicating the type of statistic\n",
    "mean_df['fold'] = 'mean'\n",
    "std_df['fold'] = 'std_dev'\n",
    "\n",
    "# Merge results vertically\n",
    "result = pd.concat([mean_df, std_df], axis=0).reset_index()\n",
    "\n",
    "# Save the result\n",
    "result.to_csv(os.path.join(folder, 'mlp_oversampling_mean_std.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ce586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average-mean-tabpfn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of input CSV files\n",
    "files = [\n",
    "    \"../results_TabPFN_Test_fold0.csv\",\n",
    "    \"../results_TabPFN_Test_fold1.csv\",\n",
    "    \"../results_TabPFN_Test_fold2.csv\",\n",
    "    \"../results_TabPFN_Test_fold3.csv\",\n",
    "    \"../results_TabPFN_Test_fold4.csv\"\n",
    "]\n",
    "\n",
    "# Check if all files exist\n",
    "for path in files:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Read each file and add a 'fold' identifier\n",
    "for i, file_path in enumerate(files):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['fold'] = i\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all files into a single DataFrame\n",
    "df_total = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Check if 'Threshold' column is present\n",
    "if 'Threshold' not in df_total.columns:\n",
    "    raise ValueError(\"The column 'Threshold' was not found in the CSV files.\")\n",
    "\n",
    "# Select numeric columns for statistics\n",
    "numeric_columns = df_total.select_dtypes(include='number').columns.tolist()\n",
    "columns_for_stats = ['Threshold'] + [col for col in numeric_columns if col != 'fold']\n",
    "\n",
    "# Calculate mean and standard deviation grouped by 'Threshold'\n",
    "mean_df = df_total[columns_for_stats].groupby('Threshold').mean().reset_index()\n",
    "std_df = df_total[columns_for_stats].groupby('Threshold').std().reset_index()\n",
    "\n",
    "# Add a column indicating the statistic type\n",
    "mean_df['fold'] = 'mean'\n",
    "std_df['fold'] = 'std_dev'\n",
    "\n",
    "# Ensure the same column order\n",
    "final_columns = df_total.columns.tolist()\n",
    "mean_df = mean_df[final_columns]\n",
    "std_df = std_df[final_columns]\n",
    "\n",
    "# Combine all data (original + mean + std)\n",
    "final_result = pd.concat([df_total, mean_df, std_df], ignore_index=True)\n",
    "\n",
    "# Define output folder\n",
    "output_folder = os.path.dirname(files[0])\n",
    "\n",
    "# Save final result\n",
    "final_result.to_csv(os.path.join(output_folder, '../Test_Results_Version2/TabPFN.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Statistical Test ===\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import friedmanchisquare, f\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# === Config ===\n",
    "csv_file = \"../all_models_statistics_B7.csv\"\n",
    "model_column = \"Model\"\n",
    "fold_column = \"Fold\"\n",
    "metrics = [\"TSS\", \"HSS\", \"AUC\", \"TPR\", \"TNR\", \"FPR\", \"FNR\"]\n",
    "output_csv = \"../friedman_iman_nemenyi_holm_results_B7.csv\"\n",
    "\n",
    "# === Read CSV ===\n",
    "df = pd.read_csv(csv_file, sep=\";\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\n--- Metric: {metric} ---\")\n",
    "\n",
    "    # Reshape into matrix format: each column = model, each row = fold\n",
    "    table = df.pivot(index=fold_column, columns=model_column, values=metric)\n",
    "\n",
    "    # Apply Friedman test\n",
    "    stat, p = friedmanchisquare(*[table[model] for model in table.columns])\n",
    "\n",
    "    # Parameters\n",
    "    N = table.shape[0]  # number of folds\n",
    "    k = table.shape[1]  # number of models\n",
    "\n",
    "    # Compute Imanâ€“Davenport statistic\n",
    "    F_F = ((N - 1) * stat) / (N * (k - 1) - stat)\n",
    "    df1 = k - 1\n",
    "    df2 = (k - 1) * (N - 1)\n",
    "    p_davenport = f.sf(F_F, df1, df2)  # p-value\n",
    "\n",
    "    # Compute Nemenyi post-hoc test\n",
    "    nemenyi = sp.posthoc_nemenyi_friedman(table.values)\n",
    "    nemenyi.index = table.columns\n",
    "    nemenyi.columns = table.columns\n",
    "\n",
    "    # Compute Dunn-Holm post-hoc test\n",
    "    holm_results = sp.posthoc_dunn(table.T.values, p_adjust='holm')\n",
    "    holm_results.index = table.columns\n",
    "    holm_results.columns = table.columns\n",
    "\n",
    "    # Generate only unique model comparisons (Model1 < Model2)\n",
    "    models = table.columns.tolist()\n",
    "    for i in range(len(models)):\n",
    "        for j in range(i + 1, len(models)):\n",
    "            model1 = models[i]\n",
    "            model2 = models[j]\n",
    "\n",
    "            p_nemenyi = nemenyi.loc[model1, model2]\n",
    "            p_holm = holm_results.loc[model1, model2]\n",
    "\n",
    "            rows.append({\n",
    "                \"Metric\": metric,\n",
    "                \"Friedman_Stat\": stat,\n",
    "                \"p_value_Friedman\": p,\n",
    "                \"ImanDavenport_Stat\": F_F,\n",
    "                \"p_value_ImanDavenport\": p_davenport,\n",
    "                \"Model1\": model1,\n",
    "                \"Model2\": model2,\n",
    "                \"p_value_Nemenyi\": p_nemenyi,\n",
    "                \"p_value_Holm\": p_holm\n",
    "            })\n",
    "\n",
    "# Save all results to CSV\n",
    "pd.DataFrame(rows).to_csv(output_csv, index=False, float_format=\"%.8f\")\n",
    "\n",
    "print(f\"\\nFile generated: {output_csv}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
